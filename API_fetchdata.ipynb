{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f501a13",
   "metadata": {},
   "source": [
    "## Implementing a data source: retrieving data from a public API, mapping it to a small data model, and storing it in a Mongo database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bc69c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "783116b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    " \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
    " \"title\": \"Clinical Trial Metadata\",\n",
    " \"type\": \"object\",\n",
    " \"properties\": {\n",
    " \"trialId\": {\n",
    " \"type\": \"string\",\n",
    " \"description\": \"A unique identifier for the clinical trial.\"\n",
    " },\n",
    " \"title\": {\n",
    " \"type\": \"string\",\n",
    " \"description\": \"The official title of the clinical trial.\"\n",
    " },\n",
    " \"startDate\": {\n",
    " \"type\": \"string\",\n",
    " \"format\": \"date\",\n",
    " \"description\": \"The start date of the clinical trial.\"\n",
    " },\n",
    " \"endDate\": {\n",
    " \"type\": \"string\",\n",
    " \"format\": \"date\",\n",
    " \"description\": \"The end date of the clinical trial, if applicable.\"\n",
    " },\n",
    " \"phase\": {\n",
    " \"type\": \"string\",\n",
    " \"enum\": [\"Phase 1\", \"Phase 2\", \"Phase 3\", \"Phase 4\", \"Other\"],\n",
    " \"description\": \"The phase of the clinical trial.\"\n",
    " },\n",
    " \"principalInvestigator\": {\n",
    " \"type\": \"object\",\n",
    " \"properties\": {\n",
    " \"name\": {\"type\": \"string\",\n",
    " \"description\": \"The name of the principal investigator.\"\n",
    " },\n",
    " \"affiliation\": {\n",
    " \"type\": \"string\",\n",
    " \"description\": \"The affiliation of the principal investigator.\"\n",
    " }\n",
    " },\n",
    " \"required\": [\"name\"]\n",
    " },\n",
    " \"locations\": {\n",
    " \"type\": \"array\",\n",
    " \"items\": {\n",
    " \"type\": \"object\",\n",
    " \"properties\": {\n",
    " \"facility\": {\n",
    " \"type\": \"string\",\n",
    " \"description\": \"Name of the facility where the trial is conducted.\"\n",
    " },\n",
    " \"city\": {\n",
    " \"type\": \"string\",\n",
    " \"description\": \"The city where the facility is located.\"\n",
    " },\n",
    " \"country\": {\n",
    " \"type\": \"string\",\n",
    " \"description\": \"The country where the facility is located.\"\n",
    " }\n",
    " }\n",
    " }\n",
    " },\n",
    " \"eligibilityCriteria\": {\n",
    " \"type\": \"string\",\n",
    " \"description\": \"A description of the eligibility criteria for the trial.\"\n",
    " }\n",
    " },\n",
    " \"required\": [\"trialId\", \"title\", \"phase\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba0a4ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint \n",
    "\n",
    "pp = pprint.PrettyPrinter(sort_dicts=True)\n",
    "# pp.pprint(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86017388",
   "metadata": {},
   "source": [
    "### Using the clinicaltrials.gov API, retrieve all studies that have been last updated between 20 and 21 October 2024. (A “last update” date is available per study.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d055a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NF0g5JuGl_gq\n",
      "NF0g5JKBlvcqwQ\n",
      "NF0g5JGDlvgowg\n",
      "NF0g5JCHlfEsxw\n",
      "NF0g5JCClvguwg\n",
      "NF0g5JCOkfUrww\n",
      "NF0g5JeBkfIvwQ\n",
      "NF0g5JaGl_csww\n",
      "NF0g5JaBlPIgxQ\n",
      "NF0g5JWDm_UowQ\n",
      "NF0g5JWOlPIvxw\n",
      "NF0g5JSOlfIryA\n",
      "NF0g5JuDm_Qtww\n",
      "NF0g5JqGkfEgxw\n",
      "NF0g5JKHkvIrwQI\n",
      "NF0g5JKHmvYtxg4\n",
      "NF0g5JKGkPUtwQM\n",
      "NF0g5JKGlfEpxQU\n",
      "NF0g5JKFkPYsxQI\n",
      "NF0g5JKEkvAuyAY\n",
      "NF0g5JKEl_AvyQA\n",
      "NF0g5JKDkvgtwgI\n",
      "NF0g5JKDl_AswQA\n",
      "NF0g5JKCkvYowwM\n",
      "NF0g5JKClPcgxwM\n",
      "NF0g5JKBlPAvxw4\n",
      "NF0g5JKAkvEgyAY\n",
      "NF0g5JKAlvAhxA4\n",
      "NF0g5JKPkvcowAI\n",
      "NF0g5JKPlfIsyA8\n",
      "NF0g5JKOkfUvxg8\n",
      "NF0g5JKOm_UuxwM\n",
      "NF0g5JGHmvQvyQE\n",
      "NF0g5JGGlfUgxAI\n",
      "NF0g5JGFlvMtyQA\n",
      "NF0g5JGEkvcpwgc\n",
      "NF0g5JGElPAoyQ8\n",
      "NF0g5JGDkvYvwwY\n",
      "NF0g5JGCkvQuyQA\n",
      "NF0g5JGCl_ggwQE\n",
      "NF0g5JGBlvEpxgU\n",
      "NF0g5JGBm_UrxQI\n",
      "NF0g5JGAlfcuwQE\n",
      "NF0g5JGPlvAuwQU\n",
      "NF0g5JGPm_Uvxwc\n",
      "NF0g5JGOl_EpxgI\n",
      "NF0g5JCHkPMpww4\n",
      "NF0g5JCHm_gswAE\n",
      "NF0g5JCGl_Ihwwc\n",
      "NF0g5JCFkPMswQc\n",
      "NF0g5JCFm_crxQM\n",
      "NF0g5JCElvguwwc\n",
      "NF0g5JCDkPAhwwI\n",
      "NF0g5JCDl_AgwQ4\n",
      "NF0g5JCCkfMuxQQ\n",
      "NF0g5JCClfkpxQc\n",
      "NF0g5JCBlvUpxg4\n",
      "None\n",
      "No more pages to fetch.\n",
      "Fetched a total of 572 studies.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Base URL for ClinicalTrials.gov API\n",
    "base_url = \"https://clinicaltrials.gov/api/v2/studies\"\n",
    "\n",
    "\n",
    "# Parameters for the query\n",
    "params = {\n",
    "    \"format\": \"json\",  # Requesting JSON format\n",
    "    \"query.term\": \"AREA[LastUpdatePostDate]RANGE[2024-10-20,2024-10-21]\",  # Essie expression\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the next page token\n",
    "next_page_token = None\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "data_list = []\n",
    "\n",
    "while True:\n",
    "    if next_page_token:\n",
    "        # Add the nextPageToken to the parameters for subsequent requests\n",
    "        params[\"pageToken\"] = next_page_token\n",
    "        \n",
    "    # Sending the request\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Handling the response\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON response\n",
    "        data = response.json()\n",
    "        studies = data.get('studies', [])  # Extract the list of studies\n",
    "\n",
    "        current_path = os.getcwd()\n",
    "        data_path = os.path.join(current_path, \"rawdata\")\n",
    "        # Append studies to the data list\n",
    "        data_list.extend(studies)\n",
    "        \n",
    "        page_filename = f\"studies_page_{next_page_token}.json\" if next_page_token else \"studies_page_1.json\"\n",
    "        # dump to a json file\n",
    "        \n",
    "        with open(os.path.join(data_path, page_filename), \"w\") as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "\n",
    "    #   Check for the nextPageToken\n",
    "        next_page_token = data.get(\"nextPageToken\")\n",
    "        print(next_page_token)\n",
    "        \n",
    "        # Update the parameters with the nextPageToken\n",
    "        params[\"pageToken\"] = next_page_token\n",
    "        \n",
    "        if not next_page_token:\n",
    "            print(\"No more pages to fetch.\")\n",
    "            break\n",
    "            \n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "        break\n",
    "\n",
    "# After all pages are fetched, save all data into a single file\n",
    "with open(os.path.join(data_path, \"all_studies.json\"), \"w\") as file:\n",
    "    json.dump(data_list, file, indent=4)\n",
    "\n",
    "print(f\"Fetched a total of {len(data_list)} studies.\")\n",
    "\n",
    "#     break\n",
    "#     # Loop through each study and extract specific information\n",
    "#     for study in studies:\n",
    "#         # Safely access nested keys\n",
    "#         nctId = study['protocolSection']['identificationModule'].get('nctId', 'Unknown')\n",
    "#         overallStatus = study['protocolSection']['statusModule'].get('overallStatus', 'Unknown')\n",
    "#         startDate = study['protocolSection']['statusModule'].get('startDateStruct', {}).get('date', 'Unknown Date')\n",
    "#         conditions = ', '.join(study['protocolSection']['conditionsModule'].get('conditions', ['No conditions listed']))\n",
    "#         acronym = study['protocolSection']['identificationModule'].get('acronym', 'Unknown')\n",
    "\n",
    "#         # Extract interventions safely\n",
    "#         interventions_list = study['protocolSection'].get('armsInterventionsModule', {}).get('interventions', [])\n",
    "#         interventions = ', '.join([intervention.get('name', 'No intervention name listed') for intervention in interventions_list]) if interventions_list else \"No interventions listed\"\n",
    "\n",
    "#         # Extract locations safely\n",
    "#         locations_list = study['protocolSection'].get('contactsLocationsModule', {}).get('locations', [])\n",
    "#         locations = ', '.join([f\"{location.get('city', 'No City')} - {location.get('country', 'No Country')}\" for location in locations_list]) if locations_list else \"No locations listed\"\n",
    "\n",
    "#         # Extract dates and phases\n",
    "#         primaryCompletionDate = study['protocolSection']['statusModule'].get('primaryCompletionDateStruct', {}).get('date', 'Unknown Date')\n",
    "#         studyFirstPostDate = study['protocolSection']['statusModule'].get('studyFirstPostDateStruct', {}).get('date', 'Unknown Date')\n",
    "#         lastUpdatePostDate = study['protocolSection']['statusModule'].get('lastUpdatePostDateStruct', {}).get('date', 'Unknown Date')\n",
    "#         studyType = study['protocolSection']['designModule'].get('studyType', 'Unknown')\n",
    "#         phases = ', '.join(study['protocolSection']['designModule'].get('phases', ['Not Available']))\n",
    "\n",
    "#  # Append the data to the list as a dictionary\n",
    "#         data_list.append({\n",
    "#                 \"NCT ID\": nctId,\n",
    "#                 \"Acronym\": acronym,\n",
    "#                 \"Overall Status\": overallStatus,\n",
    "#                 \"Start Date\": startDate,\n",
    "#                 \"Conditions\": conditions,\n",
    "#                 \"Interventions\": interventions,\n",
    "#                 \"Locations\": locations,\n",
    "#                 \"Primary Completion Date\": primaryCompletionDate,\n",
    "#                 \"Study First Post Date\": studyFirstPostDate,\n",
    "#                 \"Last Update Post Date\": lastUpdatePostDate,\n",
    "#                 \"Study Type\": studyType,\n",
    "#                 \"Phases\": phases\n",
    "#             })\n",
    "#         print(lastUpdatePostDate)\n",
    "#         # Check for nextPageToken and update the params or break the loop\n",
    "#         nextPageToken = data.get('nextPageToken')\n",
    "#         if nextPageToken:\n",
    "#             params['pageToken'] = nextPageToken  # Set the pageToken for the next request\n",
    "#         else:\n",
    "#             break  # Exit the loop if no nextPageToken is present\n",
    "# else:\n",
    "#     print(\"Failed to fetch data. Status code:\", response.status_code)\n",
    "\n",
    "\n",
    "# # Create a DataFrame from the list of dictionaries\n",
    "# df = pd.DataFrame(data_list)\n",
    "\n",
    "# # Print the DataFrame\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6403297b",
   "metadata": {},
   "source": [
    "# Read the content of the 572 studies from a combined all_studies.json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb698650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f.close()\n",
    "with open(os.path.join(data_path, \"all_studies.json\")) as f:\n",
    "    combined_studies = json.load(f)\n",
    "#     print(combined_studies)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b630a145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "572"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_studies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c52ae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    " \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
    " \"title\": \"Clinical Trial Metadata\",\n",
    " \"type\": \"object\",\n",
    " \"properties\": {\n",
    " \"trialId\": {\n",
    " \"type\": \"string\",\n",
    " \"description\": \"A unique identifier for the clinical trial.\"\n",
    " },\n",
    " \"title\": {\n",
    " \"type\": \"string\",\n",
    " \"description\": \"The official title of the clinical trial.\"\n",
    " },\n",
    " \"startDate\": {\n",
    " \"type\": \"string\",\n",
    " \"format\": \"date\",\n",
    " \"description\": \"The start date of the clinical trial.\"\n",
    " },\n",
    " \"endDate\": {\n",
    " \"type\": \"string\",\n",
    " \"format\": \"date\",\n",
    " \"description\": \"The end date of the clinical trial, if applicable.\"\n",
    " },\n",
    " \"phase\": {\n",
    " \"type\": \"string\",\n",
    " \"enum\": [\"Phase 1\", \"Phase 2\", \"Phase 3\", \"Phase 4\", \"Other\"],\n",
    " \"description\": \"The phase of the clinical trial.\"\n",
    " },\n",
    " \"principalInvestigator\": {\n",
    " \"type\": \"object\",\n",
    " \"properties\": {\n",
    " \"name\": {\n",
    "      \"type\": \"string\",\n",
    " \"description\": \"The name of the principal investigator.\"\n",
    " },\n",
    " \"affiliation\": {\n",
    " \"type\": \"string\",\n",
    " \"description\": \"The affiliation of the principal investigator.\"\n",
    " }\n",
    " },\n",
    " \"required\": [\"name\"]\n",
    " },\n",
    " \"locations\": {\n",
    " \"type\": \"array\",\n",
    " \"items\": {\n",
    " \"type\": \"object\",\n",
    " \"properties\": {\n",
    " \"facility\": {\n",
    " \"type\": \"string\",\n",
    " \"description\": \"Name of the facility where the trial is conducted.\"\n",
    " },\n",
    " \"city\": {\n",
    " \"type\": \"string\",\n",
    " \"description\": \"The city where the facility is located.\"\n",
    " },\n",
    " \"country\": {\n",
    " \"type\": \"string\",\n",
    " \"description\": \"The country where the facility is located.\"\n",
    " }\n",
    " }\n",
    " }\n",
    " },\n",
    " \"eligibilityCriteria\": {\n",
    " \"type\": \"string\",\n",
    " \"description\": \"A description of the eligibility criteria for the trial.\"\n",
    " }\n",
    " },\n",
    " \"required\": [\"trialId\", \"title\", \"phase\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a9230f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'$schema': 'http://json-schema.org/draft-07/schema#',\n",
      " 'properties': {'eligibilityCriteria': {'description': 'A description of the '\n",
      "                                                       'eligibility criteria '\n",
      "                                                       'for the trial.',\n",
      "                                        'type': 'string'},\n",
      "                'endDate': {'description': 'The end date of the clinical '\n",
      "                                           'trial, if applicable.',\n",
      "                            'format': 'date',\n",
      "                            'type': 'string'},\n",
      "                'locations': {'items': {'properties': {'city': {'description': 'The '\n",
      "                                                                               'city '\n",
      "                                                                               'where '\n",
      "                                                                               'the '\n",
      "                                                                               'facility '\n",
      "                                                                               'is '\n",
      "                                                                               'located.',\n",
      "                                                                'type': 'string'},\n",
      "                                                       'country': {'description': 'The '\n",
      "                                                                                  'country '\n",
      "                                                                                  'where '\n",
      "                                                                                  'the '\n",
      "                                                                                  'facility '\n",
      "                                                                                  'is '\n",
      "                                                                                  'located.',\n",
      "                                                                   'type': 'string'},\n",
      "                                                       'facility': {'description': 'Name '\n",
      "                                                                                   'of '\n",
      "                                                                                   'the '\n",
      "                                                                                   'facility '\n",
      "                                                                                   'where '\n",
      "                                                                                   'the '\n",
      "                                                                                   'trial '\n",
      "                                                                                   'is '\n",
      "                                                                                   'conducted.',\n",
      "                                                                    'type': 'string'}},\n",
      "                                        'type': 'object'},\n",
      "                              'type': 'array'},\n",
      "                'phase': {'description': 'The phase of the clinical trial.',\n",
      "                          'enum': ['Phase 1',\n",
      "                                   'Phase 2',\n",
      "                                   'Phase 3',\n",
      "                                   'Phase 4',\n",
      "                                   'Other'],\n",
      "                          'type': 'string'},\n",
      "                'principalInvestigator': {'properties': {'affiliation': {'description': 'The '\n",
      "                                                                                        'affiliation '\n",
      "                                                                                        'of '\n",
      "                                                                                        'the '\n",
      "                                                                                        'principal '\n",
      "                                                                                        'investigator.',\n",
      "                                                                         'type': 'string'},\n",
      "                                                         'name': {'description': 'The '\n",
      "                                                                                 'name '\n",
      "                                                                                 'of '\n",
      "                                                                                 'the '\n",
      "                                                                                 'principal '\n",
      "                                                                                 'investigator.',\n",
      "                                                                  'type': 'string'}},\n",
      "                                          'required': ['name'],\n",
      "                                          'type': 'object'},\n",
      "                'startDate': {'description': 'The start date of the clinical '\n",
      "                                             'trial.',\n",
      "                              'format': 'date',\n",
      "                              'type': 'string'},\n",
      "                'title': {'description': 'The official title of the clinical '\n",
      "                                         'trial.',\n",
      "                          'type': 'string'},\n",
      "                'trialId': {'description': 'A unique identifier for the '\n",
      "                                           'clinical trial.',\n",
      "                            'type': 'string'}},\n",
      " 'required': ['trialId', 'title', 'phase'],\n",
      " 'title': 'Clinical Trial Metadata',\n",
      " 'type': 'object'}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd11e715",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_schema = {\n",
    " \"trialId\": \"NCT00560521\",\n",
    " \"title\": \"Effect of Continuous Positive Airway Pressure on Fluid Absorption Among Patients With Pleural Effusion Due to Tuberculosis\",\n",
    " \"startDate\": \"2005-03-01\",\n",
    " \"endDate\": \"2007-03-01\",\n",
    " \"phase\": \"Other\",\n",
    " \"principalInvestigator\": {\n",
    " \"name\": \"Juliana F Oliveira\",\n",
    " \"affiliation\": \"Universidade Federal do Rio de Janeiro\"\n",
    " },\n",
    " \"locations\": [\n",
    " {\n",
    " \"facility\": \"Federal University of Rio de Janeiro\",\n",
    " \"city\": \"Rio de Janeiro\",\n",
    " \"country\": \"Brazil\"\n",
    " }\n",
    " ],\n",
    " \"eligibilityCriteria\": \"Inclusion Criteria:\\n\\nConfirmed diagnosis of pleural tuberculosis.\\nPatients 18 years of age and older.\\n\\nExclusion criteria:\\n\\nBe under previous treatment of respirat ory physiotherapy.\\nIrregular use or abandonment of the anti-TB standard regimen.\\nTo fail one or more physiotherapy section.\\nTo fail one or more radiological evaluation.\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61569477",
   "metadata": {},
   "source": [
    "## The study data structure was downloaded from ClinicalTrials.gov to search for the key names as given in the example schema for mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "05474913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['trialId', 'title', 'startDate', 'endDate', 'phase', 'principalInvestigator', 'locations', 'eligibilityCriteria'])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_schema.keys() # this needs to be extracted from the downloaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "35ddc369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trialId\n",
      "['identificationModule', 'IdentificationModule', 'nctId', 'NCTId', 'nctIdAliases', 'NCTIdAlias', 'orgStudyIdInfo', 'OrgStudyIdInfo', 'id', 'OrgStudyId', 'OrgStudyIdType', 'OrgStudyIdLink', 'secondaryIdInfos', 'SecondaryIdInfo', 'id', 'SecondaryId', 'SecondaryIdType', 'SecondaryIdDomain', 'SecondaryIdLink', 'numSecondaryIds\\xa0✗', 'NumSecondaryIds', 'nctId', 'ExpandedAccessNCTId', 'statusForNctId', 'ExpandedAccessStatusForNCTId', 'nPtrsToThisExpAccNctId', 'NPtrsToThisExpAccNCTId', 'individual', 'ExpAccTypeIndividual', 'pmid', 'ReferencePMID', 'pmid', 'RetractionPMID', 'id', 'AvailIPDId']\n",
      "\n",
      "title\n",
      "['briefTitle', 'BriefTitle', 'officialTitle', 'OfficialTitle', 'investigatorTitle', 'ResponsiblePartyInvestigatorTitle', 'oldNameTitle', 'ResponsiblePartyOldNameTitle']\n",
      "\n",
      "startDate\n",
      "['startDateStruct', 'StartDateStruct', 'StartDate', 'StartDateType']\n",
      "\n",
      "endDate\n",
      "['primaryCompletionDateStruct', 'PrimaryCompletionDateStruct', 'PrimaryCompletionDate', 'PrimaryCompletionDateType', 'completionDateStruct', 'CompletionDateStruct', 'CompletionDate', 'CompletionDateType']\n",
      "\n",
      "phase\n",
      "['phases', 'Phase', 'numPhases\\xa0✗', 'NumPhases']\n",
      "\n",
      "principalInvestigator\n",
      "['investigatorFullName', 'ResponsiblePartyInvestigatorFullName', 'investigatorTitle', 'ResponsiblePartyInvestigatorTitle', 'investigatorAffiliation', 'ResponsiblePartyInvestigatorAffiliation']\n",
      "\n",
      "locations\n",
      "['contactsLocationsModule', 'ContactsLocationsModule', 'locations\\xa0⤷', 'LocationStatus', 'LocationState', 'numLocations\\xa0✗', 'NumLocations']\n",
      "\n",
      "eligibilityCriteria\n",
      "['eligibilityCriteria', 'EligibilityCriteria']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "relevant_fields = {}        # relevant fields that look like keys in example schema \n",
    "for field in example_schema.keys():\n",
    "#     print(field)\n",
    "    if field == 'trialId':\n",
    "        print(field)\n",
    "        field_original = field\n",
    "        field = 'id'\n",
    "        result = [y for y in datastruct_protocol['Piece Name'] if re.search(f\"{field}\", str(y), re.IGNORECASE)]\n",
    "        print(result)\n",
    "#         print(datastruct_protocol[datastruct_protocol['Piece Name'].isin(result)][['Piece Name', 'Classic XPath']])\n",
    "        relevant_fields.update({field_original: datastruct_protocol[datastruct_protocol['Piece Name'].isin(result)][['Piece Name', 'Classic XPath']]})\n",
    "        \n",
    "    elif field == 'endDate':\n",
    "        print(field)\n",
    "        field_original = field\n",
    "        field = 'CompletionDate'\n",
    "        result = [y for y in datastruct_protocol['Piece Name'] if re.search(f\"{field}\", str(y), re.IGNORECASE)]\n",
    "        print(result)\n",
    "        relevant_fields.update({field_original: datastruct_protocol[datastruct_protocol['Piece Name'].isin(result)][['Piece Name', 'Classic XPath']]})\n",
    "        \n",
    "    elif field == 'principalInvestigator':\n",
    "        print(field)\n",
    "        field_original = field\n",
    "        field = 'Investigator'\n",
    "        result = [y for y in datastruct_protocol['Piece Name'] if re.search(f\"{field}\", str(y), re.IGNORECASE)]\n",
    "        print(result)\n",
    "        relevant_fields.update({field_original: datastruct_protocol[datastruct_protocol['Piece Name'].isin(result)][['Piece Name', 'Classic XPath']]})\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        print(field)\n",
    "        result = [y for y in datastruct_protocol['Piece Name'] if re.search(f\"{field}\", str(y), re.IGNORECASE)]\n",
    "        print(result)\n",
    "        relevant_fields.update({field: datastruct_protocol[datastruct_protocol['Piece Name'].isin(result)][['Piece Name', 'Classic XPath']]})\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "90bf77cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manually written dict based on the keywords found from searching keys from example schema, required as the field names are different.\n",
    "field_list = {'trialId':'nctId', 'title':'officialTitle', 'startDate':'startDateStruct', 'endDate':'completionDateStruct', 'phase':'Phase', 'principalInvestigator':['investigatorFullName',  'investigatorAffiliation'], 'locations':'locations\\xa0⤷', 'eligibilityCriteria':'eligibilityCriteria'}\n",
    "\n",
    "\n",
    "def xpath(a: str) -> str:\n",
    "    '''function to modify XPath strings.'''\n",
    "    if '/' in a:\n",
    "        b = a.replace('/', '.')\n",
    "        if 'Study' in b:\n",
    "            return b.replace('.Study.', '')\n",
    "    else:\n",
    "        return a\n",
    "    \n",
    "    \n",
    "# Doesn't require now\n",
    "# Flattening the list \n",
    "# flattened_field_list = [item for sublist in field_list.values() for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
    "\n",
    "# print(flattened_field_list)\n",
    "# filtered_df_2 = filtered_df[filtered_df[\"Piece Name\"].isin(flattened_field_list)]\n",
    "\n",
    "\n",
    "# filtered_df_2['modified_key'] = [[key for key, value in field_list.items() if (isinstance(value, list) and i in value) or (i == value)][0] for i in filtered_df_2['Piece Name']]\n",
    "# print(filtered_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "14fb0ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Piece Name</th>\n",
       "      <th>Classic XPath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>completionDateStruct</td>\n",
       "      <td>protocolSection.statusModule.completionDateStruct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Piece Name                                      Classic XPath\n",
       "74  completionDateStruct  protocolSection.statusModule.completionDateStruct"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_fields_df[relevant_fields_df['Piece Name'] == 'completionDateStruct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "feeb3938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-593-e9a49ff8e2e2>:37: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  location_data = pd.Series({v: flat_json_1[v] for v in location})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "super_dict = {}\n",
    "for n, x in enumerate(combined_studies):\n",
    "#     print(n)\n",
    "    mapped_data = {}\n",
    "    flat_json_1 = flatten_json(combined_studies[n])\n",
    "#     print(flat_json_1.keys())\n",
    "    for item in field_list:\n",
    "        i = field_list[item]\n",
    "#         print(item, i, '__________________')\n",
    "        \n",
    "        if isinstance(i, list):\n",
    "#             print(i)\n",
    "            try:\n",
    "                investigater = {}\n",
    "                for f in i:\n",
    "                    col_a = xpath(relevant_fields_df[relevant_fields_df['Piece Name'] == f]['Classic XPath'].values[0])\n",
    "#                     print(col_a)\n",
    "                    try:\n",
    "                        investigater.update({f: flat_json_1[col_a]})\n",
    "                    except:\n",
    "                        pass\n",
    "                mapped_data.update({item : investigater})\n",
    "            except:\n",
    "                pass\n",
    "                        \n",
    "        else:\n",
    "            if item == 'locations':\n",
    "                col_a = xpath(relevant_fields_df[relevant_fields_df['Piece Name'] == i]['Classic XPath'].values[0])\n",
    "#                 print(col_a)\n",
    "    \n",
    "                try:\n",
    "                    location = [a for a in flat_json_1.keys() if a.startswith(str(col_a))]\n",
    "                    if len(location) == 1:\n",
    "                        mapped_data.update({item : flat_json_1[col_a]})\n",
    "                    else:\n",
    "        #             print(location)\n",
    "                        location_data = pd.Series({v: flat_json_1[v] for v in location})\n",
    "            #             print(location_data)\n",
    "                        location_df = pd.DataFrame([range(1, len(location_data.index)+1), location_data, location_data.index]).T\n",
    "\n",
    "                        location_df['keyid'] = [re.findall(r'\\d+', string)[0] for string in location_df[2]]\n",
    "                        location_df['subfield'] = [string.split('].')[1] for string in location_df[2]]\n",
    "                        loc = {}\n",
    "            #             print(location_df)\n",
    "                        for num, (g, h) in enumerate(location_df.groupby(by='keyid')):\n",
    "                            loc.update({num: {key: val for key, val in zip(h['subfield'], h[1])}})\n",
    "        #                     print()\n",
    "    #                     print(loc)\n",
    "                        mapped_data.update({item : loc})\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "            elif item == 'startDate':\n",
    "                col_a = xpath(relevant_fields_df[relevant_fields_df['Piece Name'] == field_list[item]]['Classic XPath'].values[0])\n",
    "                try:\n",
    "                    sdate = [a for a in flat_json_1.keys() if a.startswith(str(col_a))][0]\n",
    "                    mapped_data.update({item : flat_json_1[sdate]})\n",
    "#                     print(sdate)\n",
    "                except:\n",
    "                    pass\n",
    "#                 \n",
    "            elif item == 'endDate':\n",
    "                col_a = xpath(relevant_fields_df[relevant_fields_df['Piece Name'] == field_list[item]]['Classic XPath'].values[0])\n",
    "                try:\n",
    "                    edate = [a for a in flat_json_1.keys() if a.startswith(str(col_a))][0]\n",
    "                    mapped_data.update({item : flat_json_1[edate]})\n",
    "#                     print(edate)\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "            else:\n",
    "#                 print(i)\n",
    "                try:\n",
    "                    col_a = xpath(relevant_fields_df[relevant_fields_df['Piece Name'] == field_list[item]]['Classic XPath'].values[0])\n",
    "#                     print(col_a, '***')\n",
    "#                     print()\n",
    "                    mapped_data.update({item : flat_json_1[col_a]})\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "    super_dict.update({n : mapped_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "a4f9b658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data is mapped and dumped into json\n",
    "with open(os.path.join(os.getcwd(), 'mapped_clinicaldata.json'), \"w\") as f:\n",
    "    json.dump(super_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "5ea5dff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import logging\n",
    "\n",
    "\n",
    "# Preprocess relevant_fields_df into a dictionary for quick lookups\n",
    "relevant_fields_dict = relevant_fields_df.set_index(\"Piece Name\")[\"Classic XPath\"].to_dict()\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "## Manually written dict based on the keywords found from searching keys from example schema, required as the field names are different.\n",
    "field_list = {'trialId':'nctId', 'title':'officialTitle', 'startDate':'startDateStruct', 'endDate':'completionDateStruct', 'phase':'Phase', 'principalInvestigator':['investigatorFullName',  'investigatorAffiliation'], 'locations':'locations\\xa0⤷', 'eligibilityCriteria':'eligibilityCriteria'}\n",
    "\n",
    "def flatten_json(y, parent_key='', sep='.'):\n",
    "    \"\"\"\n",
    "    Flattens a nested JSON object into a single level.\n",
    "    Keys will be in the form 'parent.child.grandchild'.\n",
    "    \"\"\"\n",
    "    items = []\n",
    "    for k, v in y.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_json(v, new_key, sep=sep).items())\n",
    "        elif isinstance(v, list):\n",
    "            for i, item in enumerate(v):\n",
    "                items.extend(flatten_json({f\"{k}[{i}]\": item}, parent_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "\n",
    "def xpath(a: str) -> str:\n",
    "    \"\"\"Modify XPath strings.\"\"\"\n",
    "    if '/' not in a:\n",
    "        return a\n",
    "    b = a.replace('/', '.')\n",
    "    return b.replace('.Study.', '') if 'Study' in b else b\n",
    "\n",
    "def process_list_field(i, flat_json_1):\n",
    "    \"\"\"Handle list-type fields like 'principalInvestigator'.\"\"\"\n",
    "    investigater = {}\n",
    "    for f in i:\n",
    "        col_a = xpath(relevant_fields_dict.get(f, \"\"))\n",
    "        if col_a in flat_json_1:\n",
    "            investigater[f] = flat_json_1[col_a]\n",
    "    return investigater\n",
    "\n",
    "def process_location_field(i, flat_json_1):\n",
    "    \"\"\"Handle 'locations' field.\"\"\"\n",
    "    col_a = xpath(relevant_fields_dict.get(i, \"\"))\n",
    "    location = [key for key in flat_json_1.keys() if key.startswith(col_a)]\n",
    "    if not location:\n",
    "        return None\n",
    "    if len(location) == 1:\n",
    "        return flat_json_1[location[0]]\n",
    "\n",
    "    location_data = pd.Series({v: flat_json_1[v] for v in location})\n",
    "    location_df = pd.DataFrame(\n",
    "        {\n",
    "            \"index\": range(1, len(location_data.index) + 1),\n",
    "            \"value\": location_data.values,\n",
    "            \"full_key\": location_data.index,\n",
    "        }\n",
    "    )\n",
    "    location_df[\"keyid\"] = location_df[\"full_key\"].str.extract(r\"(\\d+)\")\n",
    "    location_df[\"subfield\"] = location_df[\"full_key\"].str.split(\"].\").str[1]\n",
    "    loc = {}\n",
    "    for num, (keyid, group) in enumerate(location_df.groupby(\"keyid\")):\n",
    "        loc[num] = dict(zip(group[\"subfield\"], group[\"value\"]))\n",
    "    return loc\n",
    "\n",
    "\n",
    "def process_mapping(combined_study):\n",
    "    # Process studies sequentially\n",
    "    super_dict = {}\n",
    "    for n, study in enumerate(combined_study):\n",
    "        print(n)\n",
    "        flat_json_1 = flatten_json(study)\n",
    "        mapped_data = {}\n",
    "        for item in field_list:\n",
    "            print(item)\n",
    "            i = field_list[item]\n",
    "            try:\n",
    "                if isinstance(i, list):\n",
    "                    mapped_data[item] = process_list_field(i, flat_json_1)\n",
    "                elif item == \"locations\":\n",
    "                    mapped_data[item] = process_location_field(i, flat_json_1)\n",
    "                elif item in [\"startDate\", \"endDate\"]:\n",
    "                    col_a = xpath(relevant_fields_dict.get(field_list[item], \"\"))\n",
    "                    sdate = next((key for key in flat_json_1.keys() if key.startswith(col_a)), None)\n",
    "                    if sdate:\n",
    "                        mapped_data[item] = flat_json_1[sdate]\n",
    "                else:\n",
    "                    col_a = xpath(relevant_fields_dict.get(field_list[item], \"\"))\n",
    "                    if col_a in flat_json_1:\n",
    "                        mapped_data[item] = flat_json_1[col_a]\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing {item} for study {n}: {e}\")\n",
    "        super_dict[n] = mapped_data\n",
    "        return super_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "4dda9080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "trialId\n",
      "title\n",
      "startDate\n",
      "endDate\n",
      "phase\n",
      "principalInvestigator\n",
      "locations\n",
      "eligibilityCriteria\n"
     ]
    }
   ],
   "source": [
    "super_dict2 = process_mapping(combined_studies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "565c9449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(super_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb4a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #This was a test to filter out classic XPaths, as some paths had \"/\", dont require now\n",
    "\n",
    "# relevant_fields_df = pd.concat(relevant_fields.values())\n",
    "\n",
    "# print(relevant_fields_df)\n",
    "# # Keep rows where column 2 does NOT contain '/'\n",
    "# filtered_df = relevant_fields_df[~relevant_fields_df[\"Classic XPath\"].str.contains(\"/\", regex=False)]\n",
    "# filtered_df.index = range(1, len(filtered_df.index)+1)\n",
    "# print(filtered_df)\n",
    "\n",
    "# filtered_schema_v1 = {}\n",
    "# for n, x in enumerate(combined_studies):\n",
    "#     flat_json = flatten_json(combined_studies[n])\n",
    "# #     print(flat_json)\n",
    "# #     print(n)\n",
    "#     results = {}\n",
    "#     for keys in filtered_df['Classic XPath']:\n",
    "# #         print(keys)\n",
    "        \n",
    "        \n",
    "#         matches = {k: v for k, v in flat_json.items() if k.startswith(keys)}\n",
    "# #         print(matches)\n",
    "#         if matches:\n",
    "# #             print(f\"Matches for {keys}: {matches}\")\n",
    "#             results.update({keys: matches})  # Store matches\n",
    "# #         else:\n",
    "# #             print(f\"No matches for {keys}\")\n",
    "# #     pp.pprint(results)\n",
    "#     filtered_schema_v1.update({n: results})\n",
    "#     break\n",
    "\n",
    "# filtered_schema_v2 = {}\n",
    "# for n, (x, y) in enumerate(filtered_schema_v1.items()):\n",
    "    \n",
    "#     nct_id = y['protocolSection.identificationModule.nctId']\n",
    "    \n",
    "#     print(nct_id)\n",
    "    \n",
    "#     # process locations data\n",
    "#     location_data = pd.Series(y['protocolSection.contactsLocationsModule.locations'])\n",
    "#     location_df = pd.DataFrame([range(1, len(location_data.index)+1), location_data, location_data.index]).T\n",
    "    \n",
    "#     location_df['keyid']z = [re.findall(r'\\d+', string)[0] for string in location_df[2]]\n",
    "#     location_df['subfield'] = [string.split('].')[1] for string in location_df[2]]\n",
    "\n",
    "# #     print(location_df)\n",
    "#     for g, h in location_df.groupby(by='keyid'):\n",
    "#         print({key: val for key, val in zip(h['subfield'], h[1])})\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "01994a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "d6ffaada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trialId\n",
      "['protocolSection.identificationModule.nctId'\n",
      " 'protocolSection.statusModule.expandedAccessInfo.nctId']\n",
      "\n",
      "title\n",
      "['protocolSection.identificationModule.officialTitle']\n",
      "\n",
      "startDate\n",
      "['/Study/ProtocolSection/StatusModule/StartDateStruct/StartDate']\n",
      "\n",
      "endDate\n",
      "['/Study/ProtocolSection/StatusModule/CompletionDateStruct/CompletionDate']\n",
      "\n",
      "phase\n",
      "['/Study/ProtocolSection/DesignModule/PhaseList/Phase']\n",
      "\n",
      "['protocolSection.sponsorCollaboratorsModule.responsibleParty.investigatorFullName']\n",
      "['protocolSection.sponsorCollaboratorsModule.responsibleParty.investigatorAffiliation']\n",
      "\n",
      "locations\n",
      "['protocolSection.contactsLocationsModule.locations']\n",
      "\n",
      "eligibilityCriteria\n",
      "['protocolSection.eligibilityModule.eligibilityCriteria']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "field_list = {'trialId':'nctId', 'title':'officialTitle', 'startDate':'StartDate', 'endDate':'CompletionDate', 'phase':'Phase', 'principalInvestigator':['investigatorFullName',  'investigatorAffiliation'], 'locations':'locations\\xa0⤷', 'eligibilityCriteria':'eligibilityCriteria'}\n",
    "\n",
    "for i, j in field_list.items():\n",
    "    \n",
    "#     print(i)\n",
    "    \n",
    "    if isinstance(j, list):\n",
    "#         print(len(j))\n",
    "#         print('yes')\n",
    "\n",
    "        for k in j:\n",
    "#             print(j, k)\n",
    "            field_name = relevant_fields[i]\n",
    "            field_xpath = field_name[field_name['Piece Name'] == k]['Classic XPath'].values\n",
    "            print(field_xpath)\n",
    "        \n",
    "#             dict_fields = [list(filter(None, re.split(r\"[./]\", x))) for x in field_xpath]\n",
    "# #             print(dict_fields)\n",
    "            \n",
    "#             for key in dict_fields:\n",
    "#                 print(key)\n",
    "#                 try:\n",
    "#                     found_terms = reduce(lambda d, k: d[k], key, combined_studies[0])\n",
    "#                     print(found_terms)\n",
    "#                 except:\n",
    "#                     pass\n",
    "            \n",
    "#             if len(dict_fields) > 1:\n",
    "#                 print('found', dict_fields)\n",
    "                \n",
    "                \n",
    "                \n",
    "#             print([x.split('.') for x in field_xpath])\n",
    "\n",
    "        \n",
    "    else:\n",
    "        print(i)\n",
    "        field_name = relevant_fields[i]\n",
    "        field_xpath = field_name[field_name['Piece Name'] == j]['Classic XPath'].values\n",
    "        print(field_xpath)\n",
    "#         dict_fields = [list(filter(None, re.split(r\"[./]\", x))) for x in field_xpath]\n",
    "#         print(dict_fields)\n",
    "#         for key in dict_fields:\n",
    "#             print(key)\n",
    "#             try:\n",
    "#                 found_terms = reduce(lambda d, k: d[k], key, combined_studies[0])\n",
    "#                 print(found_terms)\n",
    "#             except:\n",
    "#                 pass\n",
    "\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "fc39957a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dfs = [pd.DataFrame(combined_studies[n]['protocolSection']) for n, x in enumerate(combined_studies)]\n",
    "list_dfs\n",
    "concat_dfs = pd.concat(list_dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "2682e600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nctId    NCT01524276\n",
       "nctId    NCT04964960\n",
       "nctId    NCT06649682\n",
       "nctId    NCT04876482\n",
       "nctId    NCT06636682\n",
       "            ...     \n",
       "nctId    NCT05819645\n",
       "nctId    NCT06650345\n",
       "nctId    NCT03681561\n",
       "nctId    NCT06650553\n",
       "nctId    NCT03888651\n",
       "Name: identificationModule, Length: 572, dtype: object"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_dfs['identificationModule']['nctId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ecc8c90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Piece Name</th>\n",
       "      <th>Classic XPath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>briefTitle</td>\n",
       "      <td>protocolSection.identificationModule.briefTitle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>BriefTitle</td>\n",
       "      <td>/Study/ProtocolSection/IdentificationModule/Br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>officialTitle</td>\n",
       "      <td>protocolSection.identificationModule.officialT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>OfficialTitle</td>\n",
       "      <td>/Study/ProtocolSection/IdentificationModule/Of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>investigatorTitle</td>\n",
       "      <td>protocolSection.sponsorCollaboratorsModule.res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>ResponsiblePartyInvestigatorTitle</td>\n",
       "      <td>/Study/ProtocolSection/SponsorCollaboratorsMod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>oldNameTitle</td>\n",
       "      <td>protocolSection.sponsorCollaboratorsModule.res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>ResponsiblePartyOldNameTitle</td>\n",
       "      <td>/Study/ProtocolSection/SponsorCollaboratorsMod...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Piece Name  \\\n",
       "30                          briefTitle   \n",
       "31                          BriefTitle   \n",
       "32                       officialTitle   \n",
       "33                       OfficialTitle   \n",
       "144                  investigatorTitle   \n",
       "145  ResponsiblePartyInvestigatorTitle   \n",
       "148                       oldNameTitle   \n",
       "149       ResponsiblePartyOldNameTitle   \n",
       "\n",
       "                                         Classic XPath  \n",
       "30     protocolSection.identificationModule.briefTitle  \n",
       "31   /Study/ProtocolSection/IdentificationModule/Br...  \n",
       "32   protocolSection.identificationModule.officialT...  \n",
       "33   /Study/ProtocolSection/IdentificationModule/Of...  \n",
       "144  protocolSection.sponsorCollaboratorsModule.res...  \n",
       "145  /Study/ProtocolSection/SponsorCollaboratorsMod...  \n",
       "148  protocolSection.sponsorCollaboratorsModule.res...  \n",
       "149  /Study/ProtocolSection/SponsorCollaboratorsMod...  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_fields['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a49702bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eligibilityCriteria', 'EligibilityCriteria']\n"
     ]
    }
   ],
   "source": [
    "datastruct_protocol = pd.read_csv(os.getcwd()+'\\\\datastruct\\\\Protocolsection.csv', header=0, skiprows=1)\n",
    "# print(datastruct_protocol)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f1ac76f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['protocolSection', 'derivedSection', 'hasResults']) *************\n",
      "dict_keys(['nctId', 'orgStudyIdInfo', 'organization', 'briefTitle', 'officialTitle', 'acronym'])\n",
      "dict_keys(['statusVerifiedDate', 'overallStatus', 'expandedAccessInfo', 'startDateStruct', 'primaryCompletionDateStruct', 'completionDateStruct', 'studyFirstSubmitDate', 'studyFirstSubmitQcDate', 'studyFirstPostDateStruct', 'lastUpdateSubmitDate', 'lastUpdatePostDateStruct'])\n",
      "dict_keys(['responsibleParty', 'leadSponsor'])\n",
      "dict_keys(['oversightHasDmc', 'isUsExport'])\n",
      "dict_keys(['briefSummary'])\n",
      "dict_keys(['conditions'])\n",
      "dict_keys(['studyType', 'designInfo', 'enrollmentInfo'])\n",
      "dict_keys(['primaryOutcomes'])\n",
      "dict_keys(['eligibilityCriteria', 'healthyVolunteers', 'sex', 'stdAges', 'studyPopulation', 'samplingMethod'])\n",
      "dict_keys(['centralContacts', 'locations'])\n",
      "dict_keys(['references'])\n",
      "dict_keys(['ipdSharing'])\n",
      "\n",
      "dict_keys(['protocolSection', 'resultsSection', 'documentSection', 'derivedSection', 'hasResults']) *************\n",
      "dict_keys(['nctId', 'orgStudyIdInfo', 'organization', 'briefTitle', 'officialTitle'])\n",
      "dict_keys(['statusVerifiedDate', 'overallStatus', 'whyStopped', 'expandedAccessInfo', 'startDateStruct', 'primaryCompletionDateStruct', 'completionDateStruct', 'studyFirstSubmitDate', 'studyFirstSubmitQcDate', 'studyFirstPostDateStruct', 'resultsFirstSubmitDate', 'resultsFirstSubmitQcDate', 'resultsFirstPostDateStruct', 'lastUpdateSubmitDate', 'lastUpdatePostDateStruct'])\n",
      "dict_keys(['responsibleParty', 'leadSponsor'])\n",
      "dict_keys(['oversightHasDmc', 'isFdaRegulatedDrug', 'isFdaRegulatedDevice', 'isUsExport'])\n",
      "dict_keys(['briefSummary'])\n",
      "dict_keys(['conditions'])\n",
      "dict_keys(['studyType', 'phases', 'designInfo', 'enrollmentInfo'])\n",
      "dict_keys(['armGroups', 'interventions'])\n",
      "dict_keys(['primaryOutcomes', 'secondaryOutcomes', 'otherOutcomes'])\n",
      "dict_keys(['eligibilityCriteria', 'healthyVolunteers', 'sex', 'minimumAge', 'maximumAge', 'stdAges'])\n",
      "dict_keys(['overallOfficials', 'locations'])\n",
      "dict_keys(['ipdSharing'])\n",
      "\n",
      "dict_keys(['protocolSection', 'derivedSection', 'hasResults']) *************\n",
      "dict_keys(['nctId', 'orgStudyIdInfo', 'organization', 'briefTitle', 'officialTitle', 'acronym'])\n",
      "dict_keys(['statusVerifiedDate', 'overallStatus', 'expandedAccessInfo', 'startDateStruct', 'primaryCompletionDateStruct', 'completionDateStruct', 'studyFirstSubmitDate', 'studyFirstSubmitQcDate', 'studyFirstPostDateStruct', 'lastUpdateSubmitDate', 'lastUpdatePostDateStruct'])\n",
      "dict_keys(['responsibleParty', 'leadSponsor'])\n",
      "dict_keys(['oversightHasDmc', 'isFdaRegulatedDrug', 'isFdaRegulatedDevice', 'isUsExport'])\n",
      "dict_keys(['briefSummary'])\n",
      "dict_keys(['conditions'])\n",
      "dict_keys(['studyType', 'phases', 'designInfo', 'enrollmentInfo'])\n",
      "dict_keys(['armGroups', 'interventions'])\n",
      "dict_keys(['primaryOutcomes', 'secondaryOutcomes'])\n",
      "dict_keys(['eligibilityCriteria', 'healthyVolunteers', 'sex', 'minimumAge', 'stdAges'])\n",
      "dict_keys(['centralContacts', 'overallOfficials', 'locations'])\n",
      "dict_keys(['ipdSharing', 'description', 'infoTypes'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n, x in enumerate(combined_studies[:3]):\n",
    "    print(x.keys(), '*************')\n",
    "    root_dict = combined_studies[n]\n",
    "    protocol_section =  root_dict[list(x.keys())[0]]\n",
    "    for a, b in protocol_section.items():\n",
    "        print(protocol_section[a].keys())\n",
    "    print()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "58954b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NCT01524276'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_studies[0]['protocolSection']['identificationModule']['nctId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d6a5adec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCT01524276\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "for key in [x.split('.') for x in nct_id][:1]:\n",
    "#     print(key)\n",
    "    print(reduce(lambda d, k: d[k], key, combined_studies[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "0068b179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_json(y, parent_key='', sep='.'):\n",
    "    \"\"\"\n",
    "    Flattens a nested JSON object into a single level.\n",
    "    Keys will be in the form 'parent.child.grandchild'.\n",
    "    \"\"\"\n",
    "    items = []\n",
    "    for k, v in y.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_json(v, new_key, sep=sep).items())\n",
    "        elif isinstance(v, list):\n",
    "            for i, item in enumerate(v):\n",
    "                items.extend(flatten_json({f\"{k}[{i}]\": item}, parent_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "126e941d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat_json = flatten_json(combined_studies[0])\n",
    "# print(flat_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c51aff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
